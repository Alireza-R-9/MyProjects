{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Age and Gender Detection\n",
    "### Complete # TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Requirements"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-11T08:34:12.175885Z",
     "start_time": "2025-02-11T08:34:12.172815Z"
    }
   },
   "source": [
    "# Importing Requirements\n",
    "import cv2\n",
    "import time\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt"
   ],
   "outputs": [],
   "execution_count": 4
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Camera Test"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-11T08:34:13.385603Z",
     "start_time": "2025-02-11T08:34:13.382783Z"
    }
   },
   "source": [
    "def visualize_fps(image, fps: int):\n",
    "    # Check if the image is grayscale or colored.\n",
    "    # If it's grayscale, set text color to white; if colored, set text color to green.\n",
    "    if len(np.shape(image)) < 3:\n",
    "        text_color = (255, 255, 255)  # White color for grayscale images.\n",
    "    else:\n",
    "        text_color = (0, 255, 0)  # Green color for colored images.\n",
    "\n",
    "    # Define the row size for the text placement.\n",
    "    row_size = 20 \n",
    "    # Define the left margin for the text placement.\n",
    "    left_margin = 24 \n",
    "\n",
    "    # Set the font size and thickness for the text.\n",
    "    font_size = 1\n",
    "    font_thickness = 2\n",
    "\n",
    "    # Format the FPS value into a string for displaying.\n",
    "    fps_text = \"FPS = {:.1f}\".format(fps)\n",
    "    # Set the text location on the image.\n",
    "    text_location = (left_margin, row_size)\n",
    "    \n",
    "    # Place the FPS text on the image.\n",
    "    cv2.putText(\n",
    "        image,\n",
    "        fps_text,\n",
    "        text_location,\n",
    "        cv2.FONT_HERSHEY_PLAIN,\n",
    "        font_size,\n",
    "        text_color,\n",
    "        font_thickness,\n",
    "    )\n",
    "\n",
    "    # Return the modified image with the FPS text.\n",
    "    return image\n"
   ],
   "outputs": [],
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-11T08:34:18.636938Z",
     "start_time": "2025-02-11T08:34:14.203666Z"
    }
   },
   "source": [
    "# Constants for camera settings\n",
    "CAMERA_DEVICE_ID = 0  # ID for the camera device\n",
    "IMAGE_WIDTH = 800  # Width of the captured image\n",
    "IMAGE_HEIGHT = 600  # Height of the captured image\n",
    "fps = 0  # Initial Frames Per Second (FPS) value\n",
    "\n",
    "if __name__ == \"__main__\":  # Ensures that the code only runs when executed directly\n",
    "    try:\n",
    "        cap = cv2.VideoCapture(CAMERA_DEVICE_ID)  # Initialize video capture with the specified camera device ID\n",
    "\n",
    "        while True:  # Infinite loop to continuously capture frames\n",
    "\n",
    "            start_time = time.time()  # Record the start time to calculate FPS\n",
    "\n",
    "            _, frame = cap.read()  # Capture a single frame from the camera\n",
    "\n",
    "            frame = cv2.resize(frame, (IMAGE_WIDTH, IMAGE_HEIGHT))  # Resize the frame to the specified dimensions\n",
    "\n",
    "            # Display the frame with FPS overlay\n",
    "            cv2.imshow(\"frame\", visualize_fps(frame, fps)) \n",
    "\n",
    "            end_time = time.time()  # Record the end time to calculate FPS\n",
    "\n",
    "            # Calculate the time taken to process the frame\n",
    "            seconds = end_time - start_time \n",
    "            # Calculate FPS based on the time taken to process the frame\n",
    "            fps = 1.0 / seconds\n",
    "\n",
    "            # Break the loop if the 'Esc' key (ASCII 27) is pressed\n",
    "            if cv2.waitKey(33) == 27:  \n",
    "                break\n",
    "    except Exception as e:  # Handle exceptions that may occur\n",
    "        print(e)  # Print the exception message\n",
    "    finally:\n",
    "        cv2.destroyAllWindows()  # Close all OpenCV windows\n",
    "        cap.release()  # Release the camera resource\n"
   ],
   "outputs": [],
   "execution_count": 6
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading Video"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-11T08:34:44.032495Z",
     "start_time": "2025-02-11T08:34:39.775958Z"
    }
   },
   "source": [
    "# Constants for video settings\n",
    "# Define the path to the video file using os.path.join\n",
    "CAMERA_DEVICE_ID = os.path.join(\"videos\", \"my_video.mp4\")  # Path to the video file\n",
    "IMAGE_WIDTH = 1000  # Width of the displayed image\n",
    "IMAGE_HEIGHT = 600  # Height of the displayed image\n",
    "fps = 0  # Initial Frames Per Second (FPS) value\n",
    "FRAME_RATE = 30  # Desired frame rate\n",
    "DURATION = 1 / FRAME_RATE  # Duration of each frame\n",
    "\n",
    "if __name__ == \"__main__\":  # Ensures that the code only runs when executed directly\n",
    "    try:\n",
    "        cap = cv2.VideoCapture(CAMERA_DEVICE_ID)  # Initialize video capture with the specified video file path\n",
    "\n",
    "        while True:  # Infinite loop to continuously capture frames\n",
    "            start_time = time.time()  # Record the start time to calculate FPS\n",
    "\n",
    "            _, frame = cap.read()  # Capture a single frame from the video\n",
    "            frame = cv2.resize(frame, (IMAGE_WIDTH, IMAGE_HEIGHT))  # Resize the frame to the specified dimensions\n",
    "\n",
    "            end_time = time.time()  # Record the end time to calculate FPS\n",
    "\n",
    "            # Calculate the time taken to process the frame\n",
    "            seconds = end_time - start_time\n",
    "\n",
    "            # If the processing time is less than the desired frame duration, wait for the remaining time\n",
    "            if seconds < DURATION:\n",
    "                time.sleep(DURATION - seconds)\n",
    "\n",
    "            # Recalculate the time taken to process the frame including sleep time\n",
    "            seconds = time.time() - start_time\n",
    "            # Calculate FPS based on the time taken to process the frame\n",
    "            fps = 1.0 / seconds\n",
    "\n",
    "            # Display the frame with FPS overlay\n",
    "            cv2.imshow(\"frame\", visualize_fps(frame, fps))\n",
    "\n",
    "            # Break the loop if the 'Esc' key (ASCII 27) is pressed\n",
    "            if cv2.waitKey(33) == 27:  \n",
    "                break\n",
    "    except Exception as e:  # Handle exceptions that may occur\n",
    "        print(e)  # Print the exception message\n",
    "    finally:\n",
    "        cv2.destroyAllWindows()  # Close all OpenCV windows\n",
    "        cap.release()  # Release the video capture resource\n"
   ],
   "outputs": [],
   "execution_count": 7
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading Models"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-11T08:34:47.966661Z",
     "start_time": "2025-02-11T08:34:47.844946Z"
    }
   },
   "source": [
    "# File paths to the pre-trained models and configuration files.\n",
    "faceProto = os.path.join(\"models\", \"opencv_face_detector.pbtxt\")\n",
    "faceModel = os.path.join(\"models\", \"opencv_face_detector_uint8.pb\")\n",
    "ageProto = os.path.join(\"models\", \"age_deploy.prototxt\")\n",
    "ageModel = os.path.join(\"models\", \"age_net.caffemodel\")\n",
    "genderProto = os.path.join(\"models\", \"gender_deploy.prototxt\")\n",
    "genderModel = os.path.join(\"models\", \"gender_net.caffemodel\")\n",
    "\n",
    "# Mean values used for mean subtraction in preprocessing.\n",
    "MODEL_MEAN_VALUES = (78.4263377603, 87.7689143744, 114.895847746)\n",
    "\n",
    "# List of age ranges corresponding to the output of the age detection model.\n",
    "ageList = [\n",
    "    \"(0-2)\",\n",
    "    \"(4-6)\",\n",
    "    \"(8-12)\",\n",
    "    \"(15-20)\",\n",
    "    \"(25-32)\",\n",
    "    \"(38-43)\",\n",
    "    \"(48-53)\",\n",
    "    \"(60-100)\",\n",
    "]\n",
    "\n",
    "# List of gender labels corresponding to the output of the gender detection model.\n",
    "genderList = [\"Male\", \"Female\"]\n",
    "\n",
    "# Load the pre-trained models using the readNet function.\n",
    "faceNet = cv2.dnn.readNet(faceModel, faceProto)  # Load neural network to detect faces using OpenCV\n",
    "ageNet = cv2.dnn.readNet(ageModel, ageProto)  # Load age detection neural network using OpenCV\n",
    "genderNet = cv2.dnn.readNet(genderModel, genderProto)  # Load gender detection neural network using OpenCV\n"
   ],
   "outputs": [],
   "execution_count": 8
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Detect Age and Gender in a Frame"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-11T08:34:49.550441Z",
     "start_time": "2025-02-11T08:34:49.546114Z"
    }
   },
   "source": [
    "import cv2\n",
    "\n",
    "def highlightFace(net, frame, conf_threshold=0.7):\n",
    "    # Create a copy of the frame to avoid modifying the original image.\n",
    "    frameOpencvDNN = frame.copy()\n",
    "    \n",
    "    # Get the height and width of the frame.\n",
    "    frameHeight = frameOpencvDNN.shape[0]\n",
    "    frameWidth = frameOpencvDNN.shape[1]\n",
    "    \n",
    "    # Create a blob from the image for input to the neural network.\n",
    "    blob = cv2.dnn.blobFromImage(\n",
    "        frameOpencvDNN, 1.0, (300, 300), [104, 117, 123], True, False\n",
    "    )\n",
    "\n",
    "    # Set the input for the network.\n",
    "    net.setInput(blob)\n",
    "    \n",
    "    # Perform forward pass to get the detections.\n",
    "    detections = net.forward()\n",
    "\n",
    "    # Initialize an empty list to store face bounding boxes.\n",
    "    faceBoxes = []\n",
    "\n",
    "    # Iterate over all detections.\n",
    "    for i in range(detections.shape[2]):\n",
    "        # Get the confidence for the detection.\n",
    "        confidence = detections[0, 0, i, 2]\n",
    "\n",
    "        # Check if the detection confidence is above the threshold.\n",
    "        if confidence > conf_threshold:\n",
    "            # Get the coordinates of the bounding box.\n",
    "            x1 = int(detections[0, 0, i, 3] * frameWidth)\n",
    "            y1 = int(detections[0, 0, i, 4] * frameHeight)\n",
    "            x2 = int(detections[0, 0, i, 5] * frameWidth)\n",
    "            y2 = int(detections[0, 0, i, 6] * frameHeight)\n",
    "\n",
    "            # Append the bounding box to the list.\n",
    "            faceBoxes.append([x1, y1, x2, y2])\n",
    "\n",
    "            # Draw the bounding box on the frame.\n",
    "            cv2.rectangle(frameOpencvDNN, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
    "\n",
    "    # Return the frame with bounding boxes and the list of bounding boxes.\n",
    "    return frameOpencvDNN, faceBoxes\n"
   ],
   "outputs": [],
   "execution_count": 9
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-11T08:34:50.258302Z",
     "start_time": "2025-02-11T08:34:50.253202Z"
    }
   },
   "source": [
    "def detect_face_age_gender(frame, padding=20):\n",
    "    # Highlight faces in the frame using the highlightFace function\n",
    "    resultImg, faceBoxes = highlightFace(faceNet, frame)  # Use highlightFace to detect faces\n",
    "    if not faceBoxes:  # Check if any faces were detected\n",
    "        print(\"No face detected\")\n",
    "        return frame  # Return the original frame if no faces are detected\n",
    "\n",
    "    # Iterate over the detected face bounding boxes\n",
    "    for faceBox in faceBoxes:\n",
    "        # Crop the face region with padding\n",
    "        face = frame[\n",
    "            max(0, faceBox[1] - padding) : min(\n",
    "                faceBox[3] + padding, frame.shape[0] - 1\n",
    "            ),\n",
    "            max(0, faceBox[0] - padding) : min(\n",
    "                faceBox[2] + padding, frame.shape[1] - 1\n",
    "            ),\n",
    "        ]\n",
    "    \n",
    "        # Create a blob from the face region for input to the neural networks\n",
    "        blob = cv2.dnn.blobFromImage(\n",
    "            face, 1.0, (227, 227), MODEL_MEAN_VALUES, swapRB=False\n",
    "        )\n",
    "        \n",
    "        # Predict gender using the gender detection model\n",
    "        genderNet.setInput(blob)\n",
    "        genderPreds = genderNet.forward()\n",
    "        # Select the Gender with the most probability\n",
    "        gender = genderList[genderPreds[0].argmax()]\n",
    "\n",
    "        # Predict age using the age detection model\n",
    "        ageNet.setInput(blob)\n",
    "        agePreds = ageNet.forward()\n",
    "        # Select the age category with the most probability\n",
    "        age = ageList[agePreds[0].argmax()]\n",
    "        \n",
    "        # Overlay the gender and age prediction on the image\n",
    "        label = f\"{gender}, {age}\"\n",
    "        y1 = faceBox[1] - 10 if faceBox[1] - 10 > 10 else faceBox[1] + 10\n",
    "        cv2.putText(resultImg, label, (faceBox[0], y1), cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 255, 0), 2)\n",
    "        cv2.rectangle(resultImg, (faceBox[0], faceBox[1]), (faceBox[2], faceBox[3]), (0, 255, 0), 2)\n",
    "\n",
    "    return resultImg\n"
   ],
   "outputs": [],
   "execution_count": 10
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Age and Gender Detection on Image"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-11T08:34:52.133219Z",
     "start_time": "2025-02-11T08:34:51.515486Z"
    }
   },
   "source": [
    "IMAGE_ADDRESS = os.path.join(\"images\", \"my_image.jpg\")\n",
    "OUTPUT_IMAGE_ADDRESS = os.path.join(\"images\", \"output_image.jpg\")  \n",
    "\n",
    "# Load Image\n",
    "image = cv2.imread(IMAGE_ADDRESS)\n",
    "\n",
    "# Convert color map from BGR to RGB\n",
    "image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "# Detect Age and Gender\n",
    "result = detect_face_age_gender(image)  # Use the detect_face_age_gender function for age and gender prediction\n",
    "\n",
    "# Convert back to BGR for displaying with OpenCV\n",
    "result_bgr = cv2.cvtColor(result, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "# Display the result image\n",
    "cv2.imshow(\"Detected Age and Gender\", result_bgr)\n",
    "cv2.waitKey(0)  # Wait for a key press to close the window\n",
    "cv2.destroyAllWindows()  # Close the display window\n",
    "\n",
    "# Save the result image\n",
    "cv2.imwrite(OUTPUT_IMAGE_ADDRESS, result_bgr)  # Save the image to the specified path\n",
    "print(f\"Image saved as {OUTPUT_IMAGE_ADDRESS}\")  # Notify the user that the image has been saved\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image saved as images/output_image.jpg\n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Age Detection Using Webcam"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-03T09:14:46.026799Z",
     "start_time": "2025-01-03T09:14:42.614620Z"
    }
   },
   "source": [
    "# Constants for camera settings\n",
    "CAMERA_DEVICE_ID = 0  # ID for the camera device\n",
    "IMAGE_WIDTH = 800  # Width of the captured image\n",
    "IMAGE_HEIGHT = 600  # Height of the captured image\n",
    "fps = 0  # Initial Frames Per Second (FPS) value\n",
    "padding = 20  # Padding around the detected face for cropping\n",
    "\n",
    "# Define output directory\n",
    "OUTPUT_DIR = \"output_images\"\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)  # Create directory if it doesn't exist\n",
    "\n",
    "def visualize_fps(frame, fps):\n",
    "    \"\"\"Visualizes the FPS on the frame\"\"\"\n",
    "    cv2.putText(frame, f\"FPS: {fps:.2f}\", (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
    "    return frame\n",
    "\n",
    "if __name__ == \"__main__\":  # Ensures that the code only runs when executed directly\n",
    "    try:\n",
    "        cap = cv2.VideoCapture(CAMERA_DEVICE_ID)  # Initialize video capture with the specified camera device ID\n",
    "        cap.set(cv2.CAP_PROP_FRAME_WIDTH, IMAGE_WIDTH)  # Set the width of the captured image\n",
    "        cap.set(cv2.CAP_PROP_FRAME_HEIGHT, IMAGE_HEIGHT)  # Set the height of the captured image\n",
    "\n",
    "        frame_counter = 0  # Counter for saving images\n",
    "\n",
    "        while True:  # Infinite loop to continuously capture frames\n",
    "            start_time = time.time()  # Record the start time to calculate FPS\n",
    "\n",
    "            hasFrame, frame = cap.read()  # Capture a single frame from the camera\n",
    "            if not hasFrame:  # Check if the frame was captured successfully\n",
    "                cv2.waitKey()  # Wait indefinitely for a key event\n",
    "                break  # Exit the loop if no frame is captured\n",
    "\n",
    "            frame = cv2.resize(frame, (IMAGE_WIDTH, IMAGE_HEIGHT))  # Resize the frame to the specified dimensions\n",
    "            \n",
    "            # Detect age and gender using detect_face_age_gender\n",
    "            resultImg = detect_face_age_gender(frame, padding)\n",
    "\n",
    "            # Display the frame with FPS overlay\n",
    "            resultImg = visualize_fps(resultImg, fps)\n",
    "            cv2.imshow(\"Detecting age and gender\", resultImg)\n",
    "\n",
    "            # Save the processed frame every 10 frames\n",
    "            if frame_counter % 10 == 0:\n",
    "                image_filename = os.path.join(OUTPUT_DIR, f\"frame_{frame_counter}.jpg\")\n",
    "                cv2.imwrite(image_filename, resultImg)  # Save the image\n",
    "\n",
    "            frame_counter += 1\n",
    "\n",
    "            end_time = time.time()  # Record the end time to calculate FPS\n",
    "\n",
    "            # Calculate the time taken to process the frame\n",
    "            seconds = end_time - start_time\n",
    "            # Calculate FPS based on the time taken to process the frame\n",
    "            fps = 1 / seconds if seconds > 0 else 0\n",
    "\n",
    "            # Break the loop if the 'Esc' key (ASCII 27) is pressed\n",
    "            if cv2.waitKey(33) == 27:\n",
    "                break\n",
    "    except Exception as e:  # Handle exceptions that may occur\n",
    "        print(e)  # Print the exception message\n",
    "    finally:\n",
    "        cv2.destroyAllWindows()  # Close all OpenCV windows\n",
    "        cap.release()  # Release the camera resource\n"
   ],
   "outputs": [],
   "execution_count": 16
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Age and Gender Detection Using Video"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-03T09:26:35.451199Z",
     "start_time": "2025-01-03T09:26:32.826910Z"
    }
   },
   "source": [
    "# Constants for video settings\n",
    "CAMERA_DEVICE_ID = os.path.join(\"videos\", \"my_video.mp4\")  # Path to the video file\n",
    "IMAGE_WIDTH = 1000  # Width of the displayed image\n",
    "IMAGE_HEIGHT = 600  # Height of the displayed image\n",
    "fps = 0  # Initial Frames Per Second (FPS) value\n",
    "FRAME_RATE = 30  # Desired frame rate\n",
    "DURATION = 1 / FRAME_RATE  # Duration of each frame\n",
    "\n",
    "# Ensure the videos folder exists\n",
    "os.makedirs(\"videos\", exist_ok=True)\n",
    "\n",
    "# Define the output video path\n",
    "OUTPUT_VIDEO_PATH = os.path.join(\"videos\", \"output_video.mp4\")\n",
    "\n",
    "def visualize_fps(frame, fps):\n",
    "    \"\"\"Visualizes the FPS on the frame\"\"\"\n",
    "    cv2.putText(frame, f\"FPS: {fps:.2f}\", (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
    "    return frame\n",
    "\n",
    "if __name__ == \"__main__\":  # Ensures that the code only runs when executed directly\n",
    "    try:\n",
    "        # Initialize video capture with the specified video file path\n",
    "        cap = cv2.VideoCapture(CAMERA_DEVICE_ID)\n",
    "\n",
    "        # Get the video frame width and height\n",
    "        frame_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "        frame_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "\n",
    "        # Define the codec and create a VideoWriter object to save the video\n",
    "        fourcc = cv2.VideoWriter_fourcc(*'mp4v')  # Using mp4 codec\n",
    "        out = cv2.VideoWriter(OUTPUT_VIDEO_PATH, fourcc, FRAME_RATE, (IMAGE_WIDTH, IMAGE_HEIGHT))\n",
    "\n",
    "        while True:  # Infinite loop to continuously capture frames\n",
    "            start_time = time.time()  # Record the start time to calculate FPS\n",
    "\n",
    "            hasFrame, frame = cap.read()  # Capture a single frame from the video\n",
    "            if not hasFrame:  # Check if the frame was captured successfully\n",
    "                cv2.waitKey()  # Wait indefinitely for a key event\n",
    "                break  # Exit the loop if no frame is captured\n",
    "\n",
    "            frame = cv2.resize(frame, (IMAGE_WIDTH, IMAGE_HEIGHT))  # Resize the frame to the specified dimensions\n",
    "            \n",
    "            # Detect age and gender using detect_face_age_gender (assuming the function is defined elsewhere)\n",
    "            resultImg = detect_face_age_gender(frame, padding=20)\n",
    "\n",
    "            # Display the frame with FPS overlay\n",
    "            resultImg = visualize_fps(resultImg, fps)\n",
    "            cv2.imshow(\"Detecting age and gender\", resultImg)\n",
    "\n",
    "            # Write the frame to the output video\n",
    "            out.write(resultImg)\n",
    "\n",
    "            end_time = time.time()  # Record the end time to calculate FPS\n",
    "\n",
    "            # Calculate the time taken to process the frame\n",
    "            seconds = end_time - start_time\n",
    "\n",
    "            # If the processing time is less than the desired frame duration, wait for the remaining time\n",
    "            if seconds < DURATION:\n",
    "                time.sleep(DURATION - seconds)\n",
    "\n",
    "            # Recalculate the time taken to process the frame including sleep time\n",
    "            seconds = time.time() - start_time\n",
    "\n",
    "            # Calculate FPS based on the time taken to process the frame\n",
    "            fps = 1 / seconds if seconds > 0 else 0\n",
    "\n",
    "            # Break the loop if the 'Esc' key (ASCII 27) is pressed\n",
    "            if cv2.waitKey(33) == 27:\n",
    "                break\n",
    "    except Exception as e:  # Handle exceptions that may occur\n",
    "        print(e)  # Print the exception message\n",
    "    finally:\n",
    "        cv2.destroyAllWindows()  # Close all OpenCV windows\n",
    "        cap.release()  # Release the video capture resource\n",
    "        out.release()  # Release the video writer resource\n"
   ],
   "outputs": [],
   "execution_count": 22
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
